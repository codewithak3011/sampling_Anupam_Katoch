# sampling_Anupam_Katoch

This project compares different sampling techniques for creating a balanced dataset for a machine learning model. The dataset used is initially unbalanced, so appropriate over-sampling techniques are used to create a balanced dataset. Five different sampling techniques are compared, including simple random, stratified, systematic, cluster and convenience sampling which is kind of non-probability sampling. The performance of the machine learning model is evaluated using various metrics, such as accuracy, precision, recall and area under the ROC curve.

The goal of this project is to determine which sampling technique is most effective in creating a balanced dataset that leads to the best performance of the machine learning model. By comparing different techniques, this project aims to provide insights into the strengths and weaknesses of each approach, as well as their suitability for different types of datasets and machine learning models.

This project is important because unbalanced datasets are common in many real-world applications, and they can lead to biased or inaccurate machine learning models. By using appropriate sampling techniques to balance the dataset, we can improve the performance of the machine learning model and make it more useful in practical applications.
